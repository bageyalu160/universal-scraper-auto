name: pm001 AI分析任务
on:
  workflow_dispatch:
    inputs:
      data_date:
        description: 数据日期 (YYYY-MM-DD格式)
        required: true
        type: string
      data_file:
        description: 要分析的数据文件路径
        required: true
        type: string
      site_id:
        description: 网站ID
        required: true
        type: string
        default: pm001
  repository_dispatch:
    types:
      - crawler_completed
env:
  PYTHON_VERSION: '3.10'
  ANALYSIS_DIR: analysis/daily
permissions:
  contents: write
  actions: write
jobs:
  analyze-data:
    name: 分析爬虫数据
    runs-on: ubuntu-latest
    steps:
      - name: 检出仓库代码
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: 设置Python环境
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip
      - name: 安装依赖
        run: |-
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "安装必要的依赖..."
            pip install requests pandas pyyaml google-generativeai openai
          fi
      - name: 确定分析参数
        id: params
        run: |-
          # 从参数中获取数据日期和文件路径
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            DATA_DATE="${{ github.event.inputs.data_date }}"
            DATA_FILE="${{ github.event.inputs.data_file }}"
            SITE_ID="${{ github.event.inputs.site_id }}"
          elif [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            DATA_DATE="${{ github.event.client_payload.data_date }}"
            DATA_FILE="${{ github.event.client_payload.data_file }}"
            SITE_ID="${{ github.event.client_payload.site_id }}"
          else
            # 如果没有参数，尝试从状态文件获取最新数据
            if [ -f "status/crawler_status.json" ]; then
              DATA_DATE=$(jq -r '.date' status/crawler_status.json)
              DATA_FILE=$(jq -r '.file_path' status/crawler_status.json)
              SITE_ID="pm001"
            else
              echo "错误: 无法确定数据日期和文件路径"
              exit 1
            fi
          fi

          # 确保日期目录存在
          mkdir -p "${ANALYSIS_DIR}/${DATA_DATE}"

          # 检查数据文件是否存在
          if [ ! -f "${DATA_FILE}" ]; then
            echo "错误: 数据文件 ${DATA_FILE} 不存在"
            exit 1
          fi

          # 设置输出参数
          echo "data_date=${DATA_DATE}" >> $GITHUB_OUTPUT
          echo "data_file=${DATA_FILE}" >> $GITHUB_OUTPUT
          echo "site_id=${SITE_ID}" >> $GITHUB_OUTPUT
          echo "analysis_dir=${ANALYSIS_DIR}/${DATA_DATE}" >> $GITHUB_OUTPUT
          echo "设置分析参数: 日期=${DATA_DATE}, 文件=${DATA_FILE}, 站点=${SITE_ID}"
      - name: 运行AI分析
        id: run-analysis
        run: |-
          echo "开始分析数据文件: ${{ steps.params.outputs.data_file }}"

          # 运行AI分析脚本
          python scripts/ai_analyzer.py --file "${{ steps.params.outputs.data_file }}" --site "${{ steps.params.outputs.site_id }}" --output "analysis_result.tsv"

          # 检查分析结果文件
          if [ -f "analysis_result.tsv" ]; then
            echo "分析成功完成，发现结果文件"
            echo "analysis_exists=true" >> $GITHUB_OUTPUT
            
            # 复制到日期目录
            cp analysis_result.tsv "${{ steps.params.outputs.analysis_dir }}/analysis_${{ steps.params.outputs.data_date }}.tsv"
            echo "分析结果已保存到日期目录"
          else
            echo "警告：未找到分析结果文件"
            echo "analysis_exists=false" >> $GITHUB_OUTPUT
          fi
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        continue-on-error: true
      - name: 创建分析状态文件
        run: |-
          mkdir -p status
          # 创建状态文件
          if [ "${{ steps.run-analysis.outcome }}" == "success" ] && [ "${{ steps.run-analysis.outputs.analysis_exists }}" == "true" ]; then
            echo '{
              "status": "success",
              "site_id": "${{ steps.params.outputs.site_id }}",
              "date": "${{ steps.params.outputs.data_date }}",
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "data_file": "${{ steps.params.outputs.data_file }}",
              "analysis_file": "${{ steps.params.outputs.analysis_dir }}/analysis_${{ steps.params.outputs.data_date }}.tsv",
              "message": "数据分析成功完成"
            }' > status/analyzer_status.json
          else
            echo '{
              "status": "failed",
              "site_id": "${{ steps.params.outputs.site_id }}",
              "date": "${{ steps.params.outputs.data_date }}",
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "data_file": "${{ steps.params.outputs.data_file }}",
              "message": "数据分析失败或无结果"
            }' > status/analyzer_status.json
          fi
          echo "已创建分析状态文件"
      - name: 提交分析结果和状态
        run: |-
          echo "正在提交分析结果和状态..."
          # 设置git配置
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # 添加需要提交的文件
          if [ -f "analysis_result.tsv" ]; then
            git add analysis_result.tsv
          fi
          git add "${{ steps.params.outputs.analysis_dir }}/" || echo "没有分析目录变更"
          git add status/analyzer_status.json

          # 检查是否有变更需要提交
          if git diff --staged --quiet; then
            echo "没有变更需要提交"
          else
            # 创建提交
            git commit -m "自动更新：pm001分析结果 ${{ steps.params.outputs.data_date }}"
            # 推送到仓库
            git push
            echo "成功提交并推送分析结果和状态"
          fi
