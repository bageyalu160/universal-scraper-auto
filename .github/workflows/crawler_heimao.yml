name: 黑猫投诉 爬虫任务
on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 9 * * *'
env:
  PYTHON_VERSION: '3.10'
  RUN_DATE: ${{ github.event.inputs.date || '' }}
permissions:
  contents: write
  actions: write
jobs:
  scrape-website:
    name: 运行网站爬虫
    runs-on: ubuntu-latest
    steps:
      - name: 检出仓库代码
        uses: 'actions/checkout@v4'
        with:
          fetch-depth: 0
      - name: 设置日期环境变量
        run: 'echo "RUN_DATE=$(date -u +"%Y-%m-%d")" >> $GITHUB_ENV'
      - name: 设置Python环境
        uses: 'actions/setup-python@v5'
        with:
          python-version: '${{ env.PYTHON_VERSION }}'
          cache: pip
      - name: 安装依赖
        run: |-
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "安装必要的依赖..."
            pip install requests beautifulsoup4 pandas pyyaml
          fi
      - name: 创建数据目录
        run: |-
          mkdir -p data/daily
          echo "创建日期目录: data/daily/${{ env.RUN_DATE }}"
          mkdir -p data/daily/${{ env.RUN_DATE }}
      - name: 运行爬虫脚本
        id: run-scraper
        run: |-
          echo "开始运行爬虫..."
          python scripts/scraper.py --site heimao --config config/sites/heimao.yaml

          # 检查生成的文件
          if [ -f "heimao_data.json" ]; then
            echo "爬虫成功完成，发现结果文件"
            echo "file_exists=true" >> $GITHUB_OUTPUT
            echo "file_size=$(stat -c%s heimao_data.json)" >> $GITHUB_OUTPUT
            
            # 复制到日期目录
            cp heimao_data.json data/daily/${{ env.RUN_DATE }}/
            echo "数据文件已复制到日期目录"
          else
            echo "警告：未找到结果文件"
            echo "file_exists=false" >> $GITHUB_OUTPUT
            echo "file_size=0" >> $GITHUB_OUTPUT
          fi
        env:
          OPENAI_API_KEY: '${{ secrets.OPENAI_API_KEY }}'
          GEMINI_API_KEY: '${{ secrets.GEMINI_API_KEY }}'
          HEIMAO_COOKIE: '${{ secrets.HEIMAO_COOKIE }}'
          HEIMAO_KEYWORDS: ${{ vars.HEIMAO_KEYWORDS || '' }}
          ENABLE_NOTIFICATION: ${{ vars.ENABLE_NOTIFICATION || 'false' }}
          NOTIFICATION_TYPE: ${{ vars.NOTIFICATION_TYPE || 'none' }}
          NOTIFICATION_WEBHOOK: ${{ vars.NOTIFICATION_WEBHOOK || '' }}
        continue-on-error: true
      - name: 创建爬虫状态文件
        run: |-
          mkdir -p status
          # 创建状态文件
          if [ "${{ steps.run-scraper.outcome }}" == "success" ] && [ "${{ steps.run-scraper.outputs.file_exists }}" == "true" ]; then
            echo '{
              "status": "success",
              "date": "${{ env.RUN_DATE }}",
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "file_path": "data/daily/${{ env.RUN_DATE }}/heimao_data.json",
              "file_size": "${{ steps.run-scraper.outputs.file_size }}",
              "message": "爬虫运行成功，已生成数据文件"
            }' > status/crawler_status.json
          else
            echo '{
              "status": "failed",
              "date": "${{ env.RUN_DATE }}",
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "message": "爬虫运行失败或未生成文件"
            }' > status/crawler_status.json
          fi
          echo "已创建爬虫状态文件"
      - name: 提交爬虫结果和状态
        run: |-
          echo "正在提交爬虫结果和状态..."
          # 设置git配置
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # 添加需要提交的文件
          git add data/daily/${{ env.RUN_DATE }}/ || echo "没有数据目录变更"
          git add heimao_data.json || echo "没有主数据文件"
          git add status/crawler_status.json

          # 检查是否有变更需要提交
          if git diff --staged --quiet; then
            echo "没有变更需要提交"
          else
            # 创建提交
            git commit -m "自动更新：黑猫投诉爬虫数据 ${{ env.RUN_DATE }}"
            # 推送到仓库
            git push
            echo "成功提交并推送爬虫结果和状态"
          fi
      - name: 触发分析工作流
        uses: 'benc-uk/workflow-dispatch@v1'
        with:
          workflow: analyzer_heimao.yml
          token: '${{ secrets.GITHUB_TOKEN }}'
          inputs: '{"data_date": "${{ env.RUN_DATE }}", "data_file": "data/daily/${{ env.RUN_DATE
            }}/heimao_data.json", "site_id": "heimao"}'
        if: ${{ steps.run-scraper.outputs.file_exists == 'true' }}
