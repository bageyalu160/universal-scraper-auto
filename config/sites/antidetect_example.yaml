# 反爬示例配置
# 演示如何配置代理池和反爬机制

# 基本站点信息
site:
  name: "反爬示例"
  description: "演示代理池和反爬机制的集成"
  base_url: "https://example.com"
  output_filename: "antidetect_data.json"
  encoding: "utf-8"

# 爬取规则
scraping:
  # 爬虫引擎设置
  engine: "custom" # 使用自定义引擎
  custom_module: "src.scrapers.integration_example"
  custom_function: "scrape_with_antidetect"

  # 代理池设置
  proxy:
    enable: true # 是否启用代理
    rotate: true # 是否轮换代理
    rotate_interval: 5 # 每爬取5个页面更换代理
    max_fails: 3 # 代理最大失败次数
    sources:
      # API源
      - type: "api"
        url: "${PROXY_API_URL}" # 从环境变量读取
        headers:
          Authorization: "Bearer ${PROXY_API_KEY}"
        params:
          country: "CN,US,JP" # 指定国家
          type: "https" # 代理类型
          anonymity: "high" # 匿名程度
      # 文件源
      - type: "file"
        path: "data/proxies/custom_proxies.txt"

    # 代理测试设置
    test:
      urls:
        - "https://www.baidu.com"
        - "https://www.qq.com"
      timeout: 5 # 超时秒数
      retry: 2 # 测试重试次数

  # 反爬机制设置
  anti_detection:
    # 浏览器指纹
    browser_fingerprint:
      enable: true # 是否启用浏览器指纹
      device_types: ["desktop", "mobile"] # 支持的设备类型
      consistency: true # 保持会话一致性

    # 请求头管理
    headers:
      randomize: true # 是否随机化请求头
      custom_headers:
        Referer: "https://www.example.com/"

    # 验证码解决方案
    captcha:
      enable: true # 是否启用验证码处理
      default_provider: "2captcha" # 默认服务商
      providers:
        - name: "2captcha"
          api_key: "${CAPTCHA_API_KEY}"
          priority: 1
        - name: "anti-captcha"
          api_key: "${ANTI_CAPTCHA_KEY}"
          priority: 2

    # 访问行为模拟
    behavior:
      random_delays:
        enable: true
        min_seconds: 1.0
        max_seconds: 5.0
      page_interactions:
        enable: true # 是否模拟页面交互
        scroll: true # 是否模拟滚动
        mouse_move: true # 是否模拟鼠标移动

    # 爬取频率控制
    rate_limiting:
      enable: true
      requests_per_minute: 20
      pages_per_session: 50 # 每个会话最多爬取的页面数

  # 页面抓取设置
  targets:
    - type: "category"
      url: "https://example.com/category/1"
      pages: 3
    - type: "category"
      url: "https://example.com/category/2"
      pages: 3

  # 分页设置
  pagination:
    type: "url_param" # url参数式分页
    param_name: "page"
    start_index: 1
    pages_per_target: 5

  # 错误处理
  error_handling:
    max_retries: 3
    retry_delay: 5
    fail_on_captcha: false # 遇到验证码是否失败
    skip_failed_pages: true # 是否跳过失败的页面

  # 网络请求设置
  network:
    timeout: 30
    retry_codes: [429, 500, 502, 503, 504]
    max_connections: 10
    connection_timeout: 10

# 解析设置
parsing:
  extractor: "css" # 使用CSS选择器
  item_selector: ".item"
  field_selectors:
    title: ".title"
    price: ".price"
    description: ".description"
    image: "img.product-image@src"
    url: "a.product-link@href"

# 输出设置
output:
  format: "json"
  filename: "antidetect_example_data.json"
  fields:
    - title
    - price
    - description
    - image
    - url
    - crawled_at

  # 添加时间戳
  add_timestamp: true
  timestamp_field: "crawled_at"
  timestamp_format: "%Y-%m-%d %H:%M:%S"

# 调度设置
schedule:
  cron: "0 3 * * *" # 每天凌晨3点运行
  max_runtime: 3600 # 最大运行时间（秒）

# 通知设置
notification:
  enabled: ${ENABLE_NOTIFICATION:-false}
  channels:
    - type: "${NOTIFICATION_TYPE:-none}" # 钉钉、飞书或企业微信
      webhook: "${NOTIFICATION_WEBHOOK}"
