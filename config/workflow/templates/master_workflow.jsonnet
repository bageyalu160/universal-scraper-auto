// ä¸»è°ƒåº¦å·¥ä½œæµæ¨¡æ¿ - Jsonnetç‰ˆæœ¬ (å¢å¼ºç‰ˆ)
// ä¿®å¤ç‰ˆæœ¬ - å·²ä¿®å¤ä»¥ä¸‹é—®é¢˜ï¼š
// 1. âœ… ä¿®å¤è¯­æ³•é”™è¯¯ï¼ˆscheduleæ•°ç»„æ ¼å¼ï¼‰
// 2. âœ… æ›´æ–°æ•°æ®ç›®å½•è·¯å¾„é€»è¾‘ï¼ˆä½¿ç”¨data/daily/$DATEç»“æ„ï¼‰
// 3. âœ… æ”¹è¿›é”™è¯¯å¤„ç†æœºåˆ¶ï¼ˆå®½æ¾çš„é”™è¯¯å¤„ç†ï¼Œä¸ä¸­æ–­æµç¨‹ï¼‰
// 4. âœ… æ·»åŠ æ¡ä»¶æ‰§è¡Œé€»è¾‘ï¼ˆä»…åœ¨æ•°æ®æ–‡ä»¶å­˜åœ¨æ—¶è§¦å‘åˆ†æï¼‰
// 5. âœ… ä½¿ç”¨å…¬å…±å‡½æ•°ä¼˜åŒ–ä»£ç ç»“æ„å’Œå¯ç»´æŠ¤æ€§

local params = import 'params.libsonnet';
local utils = import 'utils.libsonnet';

// å¤–éƒ¨å‚æ•°
local global_config = std.parseJson(std.extVar('global_config'));

// ç¼“å­˜é…ç½®
local cache_config = utils.generateCacheConfig('master', 'workflow');

// è¶…æ—¶è®¾ç½®
local setup_timeout = utils.getJobTimeout('setup', global_config);
local summary_timeout = utils.getJobTimeout('setup', global_config) / 2;

// é”™è¯¯å¤„ç†ç­–ç•¥
local master_error_strategy = utils.getErrorHandlingStrategy('master_workflow', global_config);

// ç¯å¢ƒå˜é‡
local workflow_env = utils.generateWorkflowEnv('master', global_config);

{
  name: 'ä¸»è°ƒåº¦å·¥ä½œæµ',
  'run-name': 'ğŸš€ ä¸»è°ƒåº¦å·¥ä½œæµ #${{ github.run_number }} (${{ github.actor }})',
  
  on: utils.generateWorkflowDispatchTrigger({
    action: {
      description: 'æ‰§è¡Œæ“ä½œ',
      required: true,
      type: 'choice',
      options: [
        'crawl_all',
        'analyze_all',
        'update_dashboard',
        'update_proxy_pool',
        'full_pipeline'
      ]
    },
    site_id: {
      description: 'ç«™ç‚¹ID (ä»…é€‚ç”¨äºå•ç«™ç‚¹æ“ä½œ)',
      required: false,
      type: 'string'
    },
    date: {
      description: 'æ•°æ®æ—¥æœŸ (ç•™ç©ºåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ)',
      required: false,
      type: 'string'
    }
  }) + utils.generateScheduleTrigger('0 0 * * *'),
  
  permissions: {
    contents: 'write',
    actions: 'write',
    pages: 'write',
    'id-token': 'write'
  },
  
  // å¹¶å‘æ§åˆ¶ - é¿å…ä¸»å·¥ä½œæµå¹¶è¡Œè¿è¡Œ
  concurrency: utils.generateConcurrencyConfig('master', 'workflow'),
  
  // å…¨å±€ç¯å¢ƒå˜é‡
  env: workflow_env,
  
  jobs: {
    // å‡†å¤‡ç¯å¢ƒä»»åŠ¡
    setup: {
      name: 'å‡†å¤‡ç¯å¢ƒ',
      'runs-on': params.runtime.runner,
      'timeout-minutes': setup_timeout,
      outputs: {
        date: '${{ steps.set-date.outputs.date }}',
        sites: '${{ steps.list-sites.outputs.sites }}'
      },
      steps: [
        utils.generateCheckoutStep(),
        {
          name: 'è®¾ç½®æ—¥æœŸ',
          id: 'set-date',
          run: |||
            if [ -n "${{ github.event.inputs.date }}" ]; then
              echo "date=${{ github.event.inputs.date }}" >> $GITHUB_OUTPUT
            else
              echo "date=$(date +%Y-%m-%d)" >> $GITHUB_OUTPUT
            fi
          |||
        },
        {
          name: 'åˆ—å‡ºå¯ç”¨ç«™ç‚¹',
          id: 'list-sites',
          run: |||
            if [ -n "${{ github.event.inputs.site_id }}" ]; then
              SITES="[\"${{ github.event.inputs.site_id }}\"]"
            else
              SITES="["
              FIRST=true
              for site in config/sites/*.yaml; do
                SITE_ID=$(basename $site .yaml)
                if [ "$SITE_ID" = "example" ]; then
                  continue
                fi
                if [ "$FIRST" = true ]; then
                  FIRST=false
                else
                  SITES="$SITES,"
                fi
                SITES="$SITES\"$SITE_ID\""
              done
              SITES="$SITES]"
            fi
            echo "sites=$SITES" >> $GITHUB_OUTPUT
            echo "å‘ç°ç«™ç‚¹: $SITES"
          |||
        },
        {
          name: 'ç¯å¢ƒä¿¡æ¯æ”¶é›†',
          run: |||
            echo "=== ç¯å¢ƒä¿¡æ¯ ==="
            echo "è¿è¡Œæ—¶é—´: $(date)"
            echo "è§¦å‘æ–¹å¼: ${{ github.event_name }}"
            echo "æ“ä½œç±»å‹: ${{ github.event.inputs.action || 'å®šæ—¶ä»»åŠ¡' }}"
            echo "æŒ‡å®šç«™ç‚¹: ${{ github.event.inputs.site_id || 'å…¨éƒ¨ç«™ç‚¹' }}"
            echo "æŒ‡å®šæ—¥æœŸ: ${{ github.event.inputs.date || 'å½“å‰æ—¥æœŸ' }}"
            echo "è¿è¡ŒID: ${{ github.run_id }}"
            echo "=== é¡¹ç›®ç»“æ„æ£€æŸ¥ ==="
            ls -la config/sites/ | head -10
            echo "=== æ•°æ®ç›®å½•æ£€æŸ¥ ==="
            if [ -d "data/daily" ]; then
              echo "æœ€è¿‘çš„æ•°æ®ç›®å½•:"
              ls -la data/daily/ | tail -5
            else
              echo "æ•°æ®ç›®å½•ä¸å­˜åœ¨"
            fi
          |||
        }
      ]
    },
    
    // ä»£ç†æ± æ›´æ–°ä»»åŠ¡
    update_proxy_pool: {
      name: 'æ›´æ–°ä»£ç†æ± ',
      needs: 'setup',
      'if': "github.event.inputs.action == 'update_proxy_pool' || github.event.inputs.action == 'full_pipeline' || github.event_name == 'schedule'",
      'runs-on': params.runtime.runner,
      steps: [
        {
          name: 'è§¦å‘ä»£ç†æ± æ›´æ–°å·¥ä½œæµ',
          uses: 'benc-uk/workflow-dispatch@v1',
          with: {
            workflow: 'proxy_pool_manager.yml',
            token: '${{ secrets.GITHUB_TOKEN }}',
            inputs: '{"action": "update"}'
          }
        }
      ]
    },
    
    // çˆ¬å–æ•°æ®ä»»åŠ¡
    crawl: {
      name: 'çˆ¬å–æ•°æ®',
      needs: ['setup', 'update_proxy_pool'],
      'if': "always() && (github.event.inputs.action == 'crawl_all' || github.event.inputs.action == 'full_pipeline' || github.event_name == 'schedule')",
      'runs-on': params.runtime.runner,
      outputs: {
        status: '${{ steps.crawl_summary.outputs.status }}',
        success_count: '${{ steps.crawl_summary.outputs.success_count }}',
        failed_count: '${{ steps.crawl_summary.outputs.failed_count }}',
        failed_sites: '${{ steps.crawl_summary.outputs.failed_sites }}'
      },
      strategy: {
        matrix: {
          site_id: '${{ fromJSON(needs.setup.outputs.sites) }}'
        },
        'fail-fast': master_error_strategy['fail-fast']
      },
      steps: [
        utils.generateCheckoutStep(),
        utils.generateDirectorySetupStep(['status/workflow']),
        {
          name: 'è§¦å‘çˆ¬è™«å·¥ä½œæµ',
          id: 'trigger_crawler',
          uses: 'benc-uk/workflow-dispatch@v1',
          with: {
            workflow: 'crawler_${{ matrix.site_id }}.yml',
            token: '${{ secrets.GITHUB_TOKEN }}',
            inputs: '{"date": "${{ needs.setup.outputs.date }}", "parent_workflow_id": "${{ github.run_id }}"}'
          }
        },
        // åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        {
          name: 'åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€',
          run: |||
            # åˆ›å»ºåˆå§‹çŠ¶æ€æ–‡ä»¶
            mkdir -p status/workflow
            cat > status/workflow/crawler_${{ matrix.site_id }}.json << EOF
            {
              "workflow_id": "${{ steps.trigger_crawler.outputs.workflow_id }}",
              "parent_workflow_id": "${{ github.run_id }}",
              "workflow_type": "crawler",
              "site_id": "${{ matrix.site_id }}",
              "status": "running",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "data_date": "${{ needs.setup.outputs.date }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ steps.trigger_crawler.outputs.workflow_id }}"
            }
            EOF
          |||
        },
        // æ£€æŸ¥çˆ¬è™«å·¥ä½œæµçŠ¶æ€
        utils.generateWorkflowStatusCheckStep('crawler', '${{ matrix.site_id }}', 300),
        // å¤„ç†çˆ¬è™«ç»“æœ
        {
          name: 'å¤„ç†çˆ¬è™«ç»“æœ',
          if: "always()",
          run: |||
            STATUS="${{ steps.check_crawler_${{ matrix.site_id }}_status.outputs.status || 'unknown' }}"
            echo "çˆ¬è™«å·¥ä½œæµçŠ¶æ€: $STATUS"
            
            if [ "$STATUS" != "success" ]; then
              echo "::warning::çˆ¬è™«å·¥ä½œæµæ‰§è¡Œå¤±è´¥æˆ–è¶…æ—¶ï¼Œç«™ç‚¹: ${{ matrix.site_id }}"
            fi
          |||
        },
        // æ±‡æ€»çˆ¬è™«ç»“æœ
        {
          name: 'æ±‡æ€»çˆ¬è™«ç»“æœ',
          id: 'crawl_summary',
          if: "always()",
          run: |||
            # è®°å½•æ¯ä¸ªç«™ç‚¹çš„çŠ¶æ€
            mkdir -p status/workflow
            
            # å†™å…¥å½“å‰çŠ¶æ€
            echo "site_id=${{ matrix.site_id }}" >> $GITHUB_OUTPUT
            echo "status=${{ steps.check_crawler_${{ matrix.site_id }}_status.outputs.status || 'unknown' }}" >> $GITHUB_OUTPUT
          |||
        }
      ]
    },
    
    // åˆ†ææ•°æ®ä»»åŠ¡
    analyze: {
      name: 'åˆ†ææ•°æ®',
      needs: ['setup', 'crawl'],
      'if': "always() && (github.event.inputs.action == 'analyze_all' || github.event.inputs.action == 'full_pipeline' || github.event_name == 'schedule')",
      'runs-on': params.runtime.runner,
      outputs: {
        status: '${{ steps.analyze_summary.outputs.status }}',
        success_count: '${{ steps.analyze_summary.outputs.success_count }}',
        failed_count: '${{ steps.analyze_summary.outputs.failed_count }}',
        failed_sites: '${{ steps.analyze_summary.outputs.failed_sites }}'
      },
      strategy: {
        matrix: {
          site_id: '${{ fromJSON(needs.setup.outputs.sites) }}'
        },
        'fail-fast': master_error_strategy['fail-fast']
      },
      steps: [
        utils.generateCheckoutStep(),
        utils.generateDirectorySetupStep(['status/workflow']),
        {
          name: 'è·å–æœ€æ–°æ•°æ®æ–‡ä»¶',
          id: 'get-latest-file',
          run: |||
            SITE_ID="${{ matrix.site_id }}"
            DATE="${{ needs.setup.outputs.date }}"
            DATA_DIR="data/daily/$DATE"
            
            echo "=== æ•°æ®æ–‡ä»¶æŸ¥æ‰¾ ==="
            echo "ç«™ç‚¹ID: $SITE_ID"
            echo "æ—¥æœŸ: $DATE"
            echo "ç›®å½•: $DATA_DIR"
            
            # æ£€æŸ¥æŒ‡å®šæ—¥æœŸç›®å½•ä¸‹çš„æ•°æ®æ–‡ä»¶
            if [ -d "$DATA_DIR" ]; then
              DATA_FILE=$(find "$DATA_DIR" -name "${SITE_ID}_*.json" -o -name "${SITE_ID}_*.csv" -o -name "${SITE_ID}_*.tsv" | head -1)
              
              if [ -n "$DATA_FILE" ] && [ -f "$DATA_FILE" ]; then
                echo "æ‰¾åˆ°æ•°æ®æ–‡ä»¶: $DATA_FILE"
                echo "data_file=$DATA_FILE" >> $GITHUB_OUTPUT
              else
                echo "åœ¨ $DATA_DIR ä¸­æœªæ‰¾åˆ° ${SITE_ID} çš„æ•°æ®æ–‡ä»¶"
                echo "data_file=" >> $GITHUB_OUTPUT
              fi
            else
              echo "$DATA_DIR ç›®å½•ä¸å­˜åœ¨"
              echo "å¯ç”¨çš„æ•°æ®ç›®å½•:"
              if [ -d "data/daily" ]; then
                ls -1 data/daily/ | tail -3
              else
                echo "data/daily ç›®å½•ä¸å­˜åœ¨"
              fi
            fi
          |||
        },
        {
          name: 'è§¦å‘åˆ†æå·¥ä½œæµ',
          id: 'trigger_analyzer',
          'if': "steps.get-latest-file.outputs.data_file != ''",
          uses: 'benc-uk/workflow-dispatch@v1',
          with: {
            workflow: 'analyzer_${{ matrix.site_id }}.yml',
            token: '${{ secrets.GITHUB_TOKEN }}',
            inputs: |||
              {
                "data_date": "${{ needs.setup.outputs.date }}",
                "data_file": "${{ steps.get-latest-file.outputs.data_file }}",
                "site_id": "${{ matrix.site_id }}",
                "parent_workflow_id": "${{ github.run_id }}"
              }
            |||
          }
        },
        // åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        {
          name: 'åˆå§‹åŒ–åˆ†æå·¥ä½œæµçŠ¶æ€',
          if: "steps.get-latest-file.outputs.data_file != ''",
          run: |||
            # åˆ›å»ºåˆå§‹çŠ¶æ€æ–‡ä»¶
            mkdir -p status/workflow
            cat > status/workflow/analyzer_${{ matrix.site_id }}.json << EOF
            {
              "workflow_id": "${{ steps.trigger_analyzer.outputs.workflow_id || '' }}",
              "parent_workflow_id": "${{ github.run_id }}",
              "workflow_type": "analyzer",
              "site_id": "${{ matrix.site_id }}",
              "status": "running",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "data_date": "${{ needs.setup.outputs.date }}",
              "data_file": "${{ steps.get-latest-file.outputs.data_file }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ steps.trigger_analyzer.outputs.workflow_id || '' }}"
            }
            EOF
          |||
        },
        // è®°å½•æ²¡æœ‰æ•°æ®æ–‡ä»¶çš„æƒ…å†µ
        {
          name: 'è®°å½•æ— æ•°æ®æ–‡ä»¶çŠ¶æ€',
          if: "steps.get-latest-file.outputs.data_file == ''",
          run: |||
            # åˆ›å»ºçŠ¶æ€æ–‡ä»¶
            mkdir -p status/workflow
            cat > status/workflow/analyzer_${{ matrix.site_id }}.json << EOF
            {
              "workflow_id": "none",
              "parent_workflow_id": "${{ github.run_id }}",
              "workflow_type": "analyzer",
              "site_id": "${{ matrix.site_id }}",
              "status": "skipped",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "data_date": "${{ needs.setup.outputs.date }}",
              "message": "æ— æ•°æ®æ–‡ä»¶å¯åˆ†æ"
            }
            EOF
          |||
        },
        // æ£€æŸ¥åˆ†æå™¨å·¥ä½œæµçŠ¶æ€
        utils.generateWorkflowStatusCheckStep('analyzer', '${{ matrix.site_id }}', 600),
        // å¤„ç†åˆ†æå™¨ç»“æœ
        {
          name: 'å¤„ç†åˆ†æå™¨ç»“æœ',
          if: "steps.get-latest-file.outputs.data_file != ''",
          run: |||
            STATUS="${{ steps.check_analyzer_${{ matrix.site_id }}_status.outputs.status || 'unknown' }}"
            echo "åˆ†æå™¨å·¥ä½œæµçŠ¶æ€: $STATUS"
            
            if [ "$STATUS" != "success" ]; then
              echo "::warning::åˆ†æå™¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥æˆ–è¶…æ—¶ï¼Œç«™ç‚¹: ${{ matrix.site_id }}"
            fi
          |||
        },
        // æ±‡æ€»åˆ†æå™¨ç»“æœ
        {
          name: 'æ±‡æ€»åˆ†æå™¨ç»“æœ',
          id: 'analyze_summary',
          if: "always()",
          run: |||
            # è®°å½•æ¯ä¸ªç«™ç‚¹çš„çŠ¶æ€
            mkdir -p status/workflow
            
            # å†™å…¥å½“å‰çŠ¶æ€
            echo "site_id=${{ matrix.site_id }}" >> $GITHUB_OUTPUT
            
            if [ "${{ steps.get-latest-file.outputs.data_file }}" == "" ]; then
              echo "status=skipped" >> $GITHUB_OUTPUT
            else
              echo "status=${{ steps.check_analyzer_${{ matrix.site_id }}_status.outputs.status || 'unknown' }}" >> $GITHUB_OUTPUT
            fi
          |||
        }
      ]
    },
    
    // æ›´æ–°ä»ªè¡¨ç›˜ä»»åŠ¡
    update_dashboard: {
      name: 'æ›´æ–°ä»ªè¡¨ç›˜',
      needs: ['setup', 'analyze'],
      'if': "always() && (github.event.inputs.action == 'update_dashboard' || github.event.inputs.action == 'full_pipeline' || github.event_name == 'schedule') && (needs.analyze.result == 'success' || needs.analyze.result == 'skipped')",
      'runs-on': params.runtime.runner,
      steps: [
        {
          name: 'è§¦å‘ä»ªè¡¨ç›˜æ›´æ–°å·¥ä½œæµ',
          uses: 'benc-uk/workflow-dispatch@v1',
          with: {
            workflow: 'update_dashboard.yml',
            token: '${{ secrets.GITHUB_TOKEN }}',
            inputs: '{"date": "${{ needs.setup.outputs.date }}"}'
          }
        }
      ]
    },
    
    // å·¥ä½œæµæ€»ç»“ä»»åŠ¡
    workflow_summary: {
      name: 'å·¥ä½œæµæ€»ç»“',
      needs: ['setup', 'update_proxy_pool', 'crawl', 'analyze', 'update_dashboard'],
      'if': 'always()',
      'runs-on': params.runtime.runner,
      'timeout-minutes': summary_timeout,
      steps: [
        utils.generateCheckoutStep(),
        utils.generateDirectorySetupStep(['status/workflow']),
        {
          name: 'ç”Ÿæˆæ‰§è¡Œæ‘˜è¦',
          id: 'workflow_summary',
          run: |||
            echo "=== ğŸš€ ä¸»å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ ==="
            echo "æ‰§è¡Œæ—¥æœŸ: ${{ needs.setup.outputs.date }}"
            echo "è§¦å‘æ–¹å¼: ${{ github.event_name }}"
            echo "æ“ä½œç±»å‹: ${{ github.event.inputs.action || 'å®šæ—¶ä»»åŠ¡' }}"
            echo "å¤„ç†ç«™ç‚¹: ${{ needs.setup.outputs.sites }}"
            echo ""
            
            # ç»Ÿè®¡å­å·¥ä½œæµçŠ¶æ€
            echo "=== ğŸ“Š å­å·¥ä½œæµçŠ¶æ€ç»Ÿè®¡ ==="
            
            # çˆ¬è™«å·¥ä½œæµç»Ÿè®¡
            CRAWLER_SUCCESS=0
            CRAWLER_FAILED=0
            CRAWLER_SKIPPED=0
            CRAWLER_UNKNOWN=0
            CRAWLER_FAILED_SITES=""
            
            # åˆ†æå™¨å·¥ä½œæµç»Ÿè®¡
            ANALYZER_SUCCESS=0
            ANALYZER_FAILED=0
            ANALYZER_SKIPPED=0
            ANALYZER_UNKNOWN=0
            ANALYZER_FAILED_SITES=""
            
            # éå†çŠ¶æ€æ–‡ä»¶ç›®å½•
            for STATUS_FILE in status/workflow/crawler_*.json; do
              if [ -f "$STATUS_FILE" ]; then
                SITE_ID=$(basename "$STATUS_FILE" | sed 's/crawler_\(.*\)\.json/\1/')
                STATUS=$(jq -r '.status' "$STATUS_FILE")
                
                case "$STATUS" in
                  "success")
                    CRAWLER_SUCCESS=$((CRAWLER_SUCCESS + 1))
                    ;;
                  "failed")
                    CRAWLER_FAILED=$((CRAWLER_FAILED + 1))
                    CRAWLER_FAILED_SITES="$CRAWLER_FAILED_SITES $SITE_ID"
                    ;;
                  "skipped")
                    CRAWLER_SKIPPED=$((CRAWLER_SKIPPED + 1))
                    ;;
                  *)
                    CRAWLER_UNKNOWN=$((CRAWLER_UNKNOWN + 1))
                    ;;
                esac
              fi
            done
            
            for STATUS_FILE in status/workflow/analyzer_*.json; do
              if [ -f "$STATUS_FILE" ]; then
                SITE_ID=$(basename "$STATUS_FILE" | sed 's/analyzer_\(.*\)\.json/\1/')
                STATUS=$(jq -r '.status' "$STATUS_FILE")
                
                case "$STATUS" in
                  "success")
                    ANALYZER_SUCCESS=$((ANALYZER_SUCCESS + 1))
                    ;;
                  "failed")
                    ANALYZER_FAILED=$((ANALYZER_FAILED + 1))
                    ANALYZER_FAILED_SITES="$ANALYZER_FAILED_SITES $SITE_ID"
                    ;;
                  "skipped")
                    ANALYZER_SKIPPED=$((ANALYZER_SKIPPED + 1))
                    ;;
                  *)
                    ANALYZER_UNKNOWN=$((ANALYZER_UNKNOWN + 1))
                    ;;
                esac
              fi
            done
            
            echo "çˆ¬è™«å·¥ä½œæµ: æˆåŠŸ=$CRAWLER_SUCCESS, å¤±è´¥=$CRAWLER_FAILED, è·³è¿‡=$CRAWLER_SKIPPED, æœªçŸ¥=$CRAWLER_UNKNOWN"
            if [ -n "$CRAWLER_FAILED_SITES" ]; then
              echo "çˆ¬è™«å¤±è´¥ç«™ç‚¹:$CRAWLER_FAILED_SITES"
            fi
            
            echo "åˆ†æå·¥ä½œæµ: æˆåŠŸ=$ANALYZER_SUCCESS, å¤±è´¥=$ANALYZER_FAILED, è·³è¿‡=$ANALYZER_SKIPPED, æœªçŸ¥=$ANALYZER_UNKNOWN"
            if [ -n "$ANALYZER_FAILED_SITES" ]; then
              echo "åˆ†æå¤±è´¥ç«™ç‚¹:$ANALYZER_FAILED_SITES"
            fi
            
            echo ""
            echo "=== ğŸ“Š å„æ­¥éª¤æ‰§è¡Œç»“æœ ==="
            echo "1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡: ${{ needs.setup.result }}"
            echo "2ï¸âƒ£ ä»£ç†æ± æ›´æ–°: ${{ needs.update_proxy_pool.result }}"
            echo "3ï¸âƒ£ æ•°æ®çˆ¬å–: ${{ needs.crawl.result }}"
            echo "4ï¸âƒ£ æ•°æ®åˆ†æ: ${{ needs.analyze.result }}"
            echo "5ï¸âƒ£ ä»ªè¡¨ç›˜æ›´æ–°: ${{ needs.update_dashboard.result }}"
            echo ""
            echo "=== ğŸ”— ç›¸å…³é“¾æ¥ ==="
            echo "å·¥ä½œæµè¿è¡Œ: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            if [[ "${{ needs.update_dashboard.result }}" == "success" ]]; then
              echo "ç›‘æ§ä»ªè¡¨ç›˜: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
            fi
            echo ""
            
            # åˆ›å»ºçŠ¶æ€æ–‡ä»¶
            mkdir -p status/workflow
            cat > status/workflow/master_workflow_summary.json << EOF
            {
              "workflow_id": "${{ github.run_id }}",
              "trigger": "${{ github.event_name }}",
              "action": "${{ github.event.inputs.action || 'å®šæ—¶ä»»åŠ¡' }}",
              "date": "${{ needs.setup.outputs.date }}",
              "sites": ${{ needs.setup.outputs.sites }},
              "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
              "results": {
                "setup": "${{ needs.setup.result }}",
                "proxy_pool": "${{ needs.update_proxy_pool.result }}",
                "crawl": "${{ needs.crawl.result }}",
                "analyze": "${{ needs.analyze.result }}",
                "dashboard": "${{ needs.update_dashboard.result }}"
              },
              "crawler_stats": {
                "success": $CRAWLER_SUCCESS,
                "failed": $CRAWLER_FAILED,
                "skipped": $CRAWLER_SKIPPED,
                "unknown": $CRAWLER_UNKNOWN,
                "failed_sites": "$CRAWLER_FAILED_SITES"
              },
              "analyzer_stats": {
                "success": $ANALYZER_SUCCESS,
                "failed": $ANALYZER_FAILED,
                "skipped": $ANALYZER_SKIPPED,
                "unknown": $ANALYZER_UNKNOWN,
                "failed_sites": "$ANALYZER_FAILED_SITES"
              },
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
            EOF
            
            # è¾“å‡ºåˆ° GITHUB_OUTPUT
            echo "crawler_success=$CRAWLER_SUCCESS" >> $GITHUB_OUTPUT
            echo "crawler_failed=$CRAWLER_FAILED" >> $GITHUB_OUTPUT
            echo "crawler_skipped=$CRAWLER_SKIPPED" >> $GITHUB_OUTPUT
            echo "crawler_failed_sites=$CRAWLER_FAILED_SITES" >> $GITHUB_OUTPUT
            
            echo "analyzer_success=$ANALYZER_SUCCESS" >> $GITHUB_OUTPUT
            echo "analyzer_failed=$ANALYZER_FAILED" >> $GITHUB_OUTPUT
            echo "analyzer_skipped=$ANALYZER_SKIPPED" >> $GITHUB_OUTPUT
            echo "analyzer_failed_sites=$ANALYZER_FAILED_SITES" >> $GITHUB_OUTPUT
            
            echo "âœ… æ‰§è¡Œæ‘˜è¦å·²ä¿å­˜åˆ° status/workflow/master_workflow_summary.json"
          |||
        },
        {
          name: 'é…ç½®Gitå¹¶æäº¤å·¥ä½œæµæ‘˜è¦',
          run: |
            # é…ç½®Git
            git config user.name "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

            # æ·»åŠ æ–‡ä»¶
            git add status/workflow/

            # æ‹‰å–è¿œç¨‹æ›´æ”¹ï¼Œé¿å…æ¨é€å†²çª
            git pull --rebase origin main || echo "æ‹‰å–è¿œç¨‹ä»“åº“å¤±è´¥ï¼Œå°è¯•ç»§ç»­æäº¤"

            # æäº¤æ›´æ”¹
            if git diff --staged --quiet; then
              echo "æ²¡æœ‰å˜æ›´éœ€è¦æäº¤"
            else
              git commit -m "ğŸ“Š è‡ªåŠ¨æ›´æ–°: ä¸»å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ (${{ needs.setup.outputs.date }})"
              git push
              echo "âœ… æˆåŠŸæäº¤å¹¶æ¨é€å·¥ä½œæµæ‘˜è¦"
            fi
          |||
        }
      ]
    },
    
    // é€šçŸ¥å®Œæˆä»»åŠ¡
    notify_completion: {
      name: 'é€šçŸ¥å®Œæˆ',
      needs: ['setup', 'update_proxy_pool', 'crawl', 'analyze', 'update_dashboard', 'workflow_summary'],
      'if': 'always()',
      'runs-on': params.runtime.runner,
      steps: [
        utils.generateCheckoutStep(),
        utils.generatePythonSetupStep(params.runtime.python_version, true),
        {
          name: 'å®‰è£…ä¾èµ–',
          run: |||
            pip install -r requirements.txt
          |||
        },
        {
          name: 'å‡†å¤‡é€šçŸ¥å†…å®¹å¹¶å‘é€',
          id: 'send_notification',
          env: {
            DINGTALK_WEBHOOK_URL: '${{ secrets.DINGTALK_WEBHOOK }}',
            FEISHU_WEBHOOK_URL: '${{ secrets.FEISHU_WEBHOOK }}',
            WECHAT_WORK_WEBHOOK_URL: '${{ secrets.WECHAT_WEBHOOK }}'
          },
          run: |||
            # åˆ›å»ºå·¥ä½œæµçŠ¶æ€æ–‡ä»¶
            mkdir -p temp-notification
            cat > temp-notification/master_workflow_status.json << EOF
            {
              "workflow_status": {
                "setup": "${{ needs.setup.result }}",
                "proxy_pool": "${{ needs.update_proxy_pool.result }}",
                "crawl": "${{ needs.crawl.result }}",
                "analyze": "${{ needs.analyze.result }}",
                "dashboard": "${{ needs.update_dashboard.result }}",
                "date": "${{ needs.setup.outputs.date }}",
                "sites": ${{ needs.setup.outputs.sites }},
                "action": "${{ github.event.inputs.action || 'å®šæ—¶ä»»åŠ¡' }}",
                "run_id": "${{ github.run_id }}",
                "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                "crawler_stats": {
                  "success": "${{ needs.workflow_summary.outputs.crawler_success || '0' }}",
                  "failed": "${{ needs.workflow_summary.outputs.crawler_failed || '0' }}",
                  "skipped": "${{ needs.workflow_summary.outputs.crawler_skipped || '0' }}",
                  "failed_sites": "${{ needs.workflow_summary.outputs.crawler_failed_sites || '' }}"
                },
                "analyzer_stats": {
                  "success": "${{ needs.workflow_summary.outputs.analyzer_success || '0' }}",
                  "failed": "${{ needs.workflow_summary.outputs.analyzer_failed || '0' }}",
                  "skipped": "${{ needs.workflow_summary.outputs.analyzer_skipped || '0' }}",
                  "failed_sites": "${{ needs.workflow_summary.outputs.analyzer_failed_sites || '' }}"
                }
              }
            }
            EOF
            
            # å‡†å¤‡é€šçŸ¥å†…å®¹
            TITLE="ğŸ“¢ Universal Scraper å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Š"
            DATE="${{ needs.setup.outputs.date }}"
            RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            
            # æ±‡æ€»æ•°æ®
            CRAWLER_SUCCESS="${{ needs.workflow_summary.outputs.crawler_success || '0' }}"
            CRAWLER_FAILED="${{ needs.workflow_summary.outputs.crawler_failed || '0' }}"
            CRAWLER_SKIPPED="${{ needs.workflow_summary.outputs.crawler_skipped || '0' }}"
            CRAWLER_FAILED_SITES="${{ needs.workflow_summary.outputs.crawler_failed_sites || '' }}"
            
            ANALYZER_SUCCESS="${{ needs.workflow_summary.outputs.analyzer_success || '0' }}"
            ANALYZER_FAILED="${{ needs.workflow_summary.outputs.analyzer_failed || '0' }}"
            ANALYZER_SKIPPED="${{ needs.workflow_summary.outputs.analyzer_skipped || '0' }}"
            ANALYZER_FAILED_SITES="${{ needs.workflow_summary.outputs.analyzer_failed_sites || '' }}"
            
            # ç”Ÿæˆé€šçŸ¥å†…å®¹
            cat > temp-notification/notification_content.md << EOF
            ### $TITLE
            
            **æ•°æ®æ—¥æœŸ:** $DATE
            
            **çˆ¬è™«ç»“æœ:**
            - æˆåŠŸ: $CRAWLER_SUCCESS
            - å¤±è´¥: $CRAWLER_FAILED
            - è·³è¿‡: $CRAWLER_SKIPPED
            EOF
            
            if [ -n "$CRAWLER_FAILED_SITES" ]; then
              echo "- å¤±è´¥ç«™ç‚¹:$CRAWLER_FAILED_SITES" >> temp-notification/notification_content.md
            fi
            
            cat >> temp-notification/notification_content.md << EOF
            
            **åˆ†æç»“æœ:**
            - æˆåŠŸ: $ANALYZER_SUCCESS
            - å¤±è´¥: $ANALYZER_FAILED
            - è·³è¿‡: $ANALYZER_SKIPPED
            EOF
            
            if [ -n "$ANALYZER_FAILED_SITES" ]; then
              echo "- å¤±è´¥ç«™ç‚¹:$ANALYZER_FAILED_SITES" >> temp-notification/notification_content.md
            fi
            
            echo -e "\n[æŸ¥çœ‹å·¥ä½œæµè¯¦æƒ…]($RUN_URL)" >> temp-notification/notification_content.md
            
            # å‘é€é€šçŸ¥
            echo "ğŸ“¢ å‘é€ä¸»å·¥ä½œæµå®Œæˆé€šçŸ¥..."
            python scripts/notify.py --file "temp-notification/master_workflow_status.json" --site "ä¸»å·¥ä½œæµ" --content "$(cat temp-notification/notification_content.md)"
          |||
        }
      ]
    }
  }
}
