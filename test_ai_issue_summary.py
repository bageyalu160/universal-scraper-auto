#!/usr/bin/env python3
"""
AI Issueæ‘˜è¦å·¥ä½œæµæµ‹è¯•è„šæœ¬
æµ‹è¯•Jsonnetæ¨¡æ¿çš„è¯­æ³•å’ŒåŠŸèƒ½
"""

import json
import os
import sys
import subprocess
import yaml
from pathlib import Path

def load_site_config(site_id):
    """åŠ è½½ç«™ç‚¹é…ç½®"""
    config_file = f"config/sites/{site_id}_ai_summary.yaml"
    if not os.path.exists(config_file):
        # ä½¿ç”¨é»˜è®¤é…ç½®
        config_file = f"config/sites/{site_id}.yaml"
        if not os.path.exists(config_file):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç«™ç‚¹é…ç½®æ–‡ä»¶ {config_file}")
            return None
    
    with open(config_file, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def test_jsonnet_template(site_id):
    """æµ‹è¯•Jsonnetæ¨¡æ¿"""
    print(f"ğŸ§ª æµ‹è¯•AI Issueæ‘˜è¦æ¨¡æ¿ - {site_id}")
    
    # åŠ è½½ç«™ç‚¹é…ç½®
    site_config = load_site_config(site_id)
    if not site_config:
        return False
    
    # å‡†å¤‡Jsonnetå‚æ•°
    site_config_json = json.dumps(site_config)
    global_config = {"runner": "ubuntu-latest", "python_version": "3.10"}
    global_config_json = json.dumps(global_config)
    
    # Jsonnetæ¨¡æ¿è·¯å¾„ - ä½¿ç”¨ä¿®å¤ç‰ˆ
    template_path = "config/workflow/templates/ai_issue_summary_fixed.jsonnet"
    
    if not os.path.exists(template_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ {template_path}")
        return False
    
    try:
        # æ„å»ºjsonnetå‘½ä»¤
        cmd = [
            "jsonnet",
            "--ext-str", f"site_id={site_id}",
            "--ext-str", f"site_config={site_config_json}",
            "--ext-str", f"global_config={global_config_json}",
            template_path
        ]
        
        print(f"ğŸ“‹ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd[:4])}...")
        
        # æ‰§è¡Œjsonnet
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ Jsonnetç¼–è¯‘å¤±è´¥:")
            print(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            return False
        
        # è§£æç”Ÿæˆçš„YAML
        try:
            workflow_yaml = yaml.safe_load(result.stdout)
            print(f"âœ… Jsonnetæ¨¡æ¿ç¼–è¯‘æˆåŠŸ!")
            
            # éªŒè¯ç”Ÿæˆçš„å·¥ä½œæµç»“æ„
            required_keys = ["name", "on", "permissions", "jobs"]
            for key in required_keys:
                if key not in workflow_yaml:
                    print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„å·¥ä½œæµç¼ºå°‘å¿…è¦å­—æ®µ '{key}'")
                    return False
            
            # æ£€æŸ¥ä½œä¸š
            if "ai-summary" not in workflow_yaml["jobs"]:
                print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„å·¥ä½œæµç¼ºå°‘ 'ai-summary' ä½œä¸š")
                return False
            
            print(f"ğŸ¯ å·¥ä½œæµåç§°: {workflow_yaml['name']}")
            print(f"ğŸ”§ ä½œä¸šæ•°é‡: {len(workflow_yaml['jobs'])}")
            print(f"ğŸ“ ä½œä¸šåˆ—è¡¨: {list(workflow_yaml['jobs'].keys())}")
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            output_file = f".github/workflows/test_ai_summary_{site_id}.yml"
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result.stdout)
            
            print(f"ğŸ’¾ æµ‹è¯•å·¥ä½œæµå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except yaml.YAMLError as e:
            print(f"âŒ ç”Ÿæˆçš„YAMLæ ¼å¼é”™è¯¯: {e}")
            return False
            
    except subprocess.SubprocessError as e:
        print(f"âŒ æ‰§è¡Œjsonnetå‘½ä»¤å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯: {e}")
        return False

def test_issue_parsing():
    """æµ‹è¯•Issueè§£æé€»è¾‘"""
    print("\nğŸ” æµ‹è¯•Issueè§£æé€»è¾‘")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "title": "é»‘çŒ«æŠ•è¯‰çˆ¬è™«å¤±è´¥",
            "body": "è¿è¡Œçˆ¬è™«æ—¶å‡ºç°è¶…æ—¶é”™è¯¯ï¼Œæ— æ³•è·å–æ•°æ®",
            "expected_labels": ["bug", "scraper", "heimao"]
        },
        {
            "title": "æ–°å¢æ•°æ®åˆ†æåŠŸèƒ½",
            "body": "å¸Œæœ›æ·»åŠ æŠ•è¯‰æ•°æ®çš„å¯è§†åŒ–åˆ†æåŠŸèƒ½",
            "expected_labels": ["enhancement", "data", "scraper"]
        },
        {
            "title": "ç´§æ€¥ï¼šç”Ÿäº§ç¯å¢ƒå´©æºƒ",
            "body": "ç”Ÿäº§ç¯å¢ƒçš„çˆ¬è™«ç³»ç»Ÿå®Œå…¨å´©æºƒï¼Œæ•°æ®ä¸¢å¤±",
            "expected_labels": ["bug", "urgent", "scraper"]
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ æµ‹è¯•ç”¨ä¾‹ {i}: {case['title']}")
        
        # è¿™é‡Œåªæ˜¯æ¨¡æ‹Ÿæ ‡ç­¾æ£€æµ‹é€»è¾‘
        content = (case['title'] + ' ' + case['body']).lower()
        detected_labels = []
        
        # Bugå…³é”®è¯
        bug_keywords = ['error', 'fail', 'crash', 'é”™è¯¯', 'å¤±è´¥', 'å´©æºƒ', 'bug', 'å¼‚å¸¸', 'è¶…æ—¶', 'æ— æ³•è®¿é—®']
        if any(keyword in content for keyword in bug_keywords):
            detected_labels.append('bug')
        
        # Enhancementå…³é”®è¯
        enhancement_keywords = ['feature', 'enhancement', 'improve', 'åŠŸèƒ½', 'æ”¹è¿›', 'å¢å¼º', 'ä¼˜åŒ–', 'æ–°å¢', 'æ‰©å±•']
        if any(keyword in content for keyword in enhancement_keywords):
            detected_labels.append('enhancement')
        
        # Scraperå…³é”®è¯
        scraper_keywords = ['scraper', 'crawler', 'parse', 'çˆ¬è™«', 'æŠ“å–', 'è§£æ', 'é»‘çŒ«', 'heimao', 'æŠ•è¯‰', 'æ•°æ®é‡‡é›†']
        if any(keyword in content for keyword in scraper_keywords):
            detected_labels.append('scraper')
        
        # Dataå…³é”®è¯
        data_keywords = ['æ•°æ®', 'data', 'åˆ†æ', 'analysis', 'ç»Ÿè®¡', 'æŠ¥å‘Š', 'å¯è§†åŒ–']
        if any(keyword in content for keyword in data_keywords):
            detected_labels.append('data')
        
        # Urgentå…³é”®è¯
        urgent_keywords = ['urgent', 'critical', 'blocking', 'ç´§æ€¥', 'ä¸¥é‡', 'é˜»å¡', 'ç”Ÿäº§ç¯å¢ƒ', 'æ•°æ®ä¸¢å¤±']
        if any(keyword in content for keyword in urgent_keywords):
            detected_labels.append('urgent')
        
        # Heimaoå…³é”®è¯
        if 'heimao' in content or 'é»‘çŒ«' in content:
            detected_labels.append('heimao')
        
        print(f"   æ£€æµ‹åˆ°çš„æ ‡ç­¾: {detected_labels}")
        print(f"   æœŸæœ›çš„æ ‡ç­¾: {case['expected_labels']}")
        
        # è®¡ç®—åŒ¹é…åº¦
        matched = set(detected_labels) & set(case['expected_labels'])
        match_rate = len(matched) / len(case['expected_labels']) if case['expected_labels'] else 0
        
        if match_rate >= 0.5:
            print(f"   âœ… åŒ¹é…ç‡: {match_rate:.1%} (é€šè¿‡)")
        else:
            print(f"   âš ï¸ åŒ¹é…ç‡: {match_rate:.1%} (éœ€è¦ä¼˜åŒ–)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– AI Issueæ‘˜è¦å·¥ä½œæµæµ‹è¯•")
    print("=" * 40)
    
    # æµ‹è¯•ç«™ç‚¹åˆ—è¡¨
    test_sites = ["heimao"]
    
    success_count = 0
    
    for site_id in test_sites:
        print(f"\n{'='*40}")
        if test_jsonnet_template(site_id):
            success_count += 1
    
    # æµ‹è¯•Issueè§£æé€»è¾‘
    test_issue_parsing()
    
    print(f"\n{'='*40}")
    print(f"ğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æˆåŠŸ: {success_count}/{len(test_sites)} ç«™ç‚¹")
    
    if success_count == len(test_sites):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AI Issueæ‘˜è¦åŠŸèƒ½å·²å°±ç»ªã€‚")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ¨¡æ¿ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 